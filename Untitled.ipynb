{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e259f686-90ee-462c-8498-67cf63a411be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0] D_loss: 1.3933, G_loss: 0.7344\n",
      "Generated Fake Article:\n",
      "1. Critics prime agenda strong development democracy government development party party party party progressive youth party progressive critics critics <unk> progressive progressive progressive prime critics <pad> growth <unk> democracy youth future party critics <unk> prime party rally youth youth democracy democracy media progressive party reform nation critics democracy democracy public media\n",
      "\n",
      "[Epoch 500] D_loss: 0.0003, G_loss: 9.0921\n",
      "Generated Fake Article:\n",
      "1. Agenda government government youth controversial <pad> agenda progressive agenda agenda critics critics agenda biased rights biased biased biased critics government announced announced agenda agenda agenda progressive democracy critics democracy youth government media justice strong party <unk> party progressive progressive progressive party party party <unk> progressive progressive youth progressive truth <unk>\n",
      "\n",
      "[Epoch 1000] D_loss: 0.0001, G_loss: 10.0898\n",
      "Generated Fake Article:\n",
      "1. Justice nation party party party development youth government prime strong strong strong party strong youth growth growth government party party critics critics critics critics liberty <pad> <pad> agenda agenda prime prime agenda prime critics critics progressive justice critics critics critics party democracy democracy truth democracy truth strong prime prime future\n",
      "\n",
      "[Epoch 1500] D_loss: 0.0001, G_loss: 10.8845\n",
      "Generated Fake Article:\n",
      "1. Development development critics agenda development government government development agenda agenda progressive progressive democracy democracy youth youth youth biased critics critics critics critics critics future truth party progressive critics government strong democracy <pad> party critics youth agenda agenda agenda party development party development media progressive progressive speech critics <unk> critics critics\n",
      "\n",
      "[Epoch 1999] D_loss: 0.0000, G_loss: 11.4383\n",
      "Generated Fake Article:\n",
      "1. Party party party biased nation party agenda progressive critics biased biased biased biased agenda party progressive progressive development <pad> critics critics prime prime party party growth truth justice media media progressive progressive announced <pad> youth nation youth youth party critics justice democracy agenda party agenda agenda agenda agenda youth media\n",
      "\n",
      "ðŸ§ª Bias/Fake Score: 46.81% likely to be fake or biased.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# === Config ===\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "VOCAB = ['<PAD>', '<UNK>'] + [\n",
    "    'party', 'election', 'government', 'youth', 'change', 'freedom', 'nation',\n",
    "    'leader', 'policy', 'future', 'supporters', 'progressive', 'reform', 'economy',\n",
    "    'rights', 'development', 'agenda', 'unity', 'growth', 'platform', 'claims',\n",
    "    'announced', 'speech', 'today', 'social', 'media', 'president', 'prime',\n",
    "    'minister', 'parliament', 'country', 'people', 'vote', 'public', 'justice',\n",
    "    'campaign', 'fake', 'truth', 'biased', 'controversial', 'statement', 'agenda',\n",
    "    'democracy', 'freedom', 'liberty', 'strong', 'support', 'critics', 'rally'\n",
    "]\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "WORD2IDX = {w: i for i, w in enumerate(VOCAB)}\n",
    "IDX2WORD = {i: w for w, i in WORD2IDX.items()}\n",
    "SEQ_LEN = 50\n",
    "NOISE_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "# === Tokenization Utilities ===\n",
    "def tokenize(text):\n",
    "    return [WORD2IDX.get(w.lower(), WORD2IDX['<UNK>']) for w in text.split()][:SEQ_LEN]\n",
    "\n",
    "def detokenize(tokens):\n",
    "    return ' '.join([IDX2WORD.get(tok, '<UNK>') for tok in tokens])\n",
    "\n",
    "def pad_sequence(seq):\n",
    "    return seq + [0] * (SEQ_LEN - len(seq))\n",
    "\n",
    "# === Generator ===\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(NOISE_DIM, HIDDEN_DIM, batch_first=True)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out, _ = self.rnn(noise)\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "# === Discriminator ===\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(VOCAB_SIZE, HIDDEN_DIM)\n",
    "        self.rnn = nn.LSTM(HIDDEN_DIM, HIDDEN_DIM, batch_first=True)\n",
    "        self.attn = nn.Linear(HIDDEN_DIM, 1)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embed(x)\n",
    "        rnn_out, _ = self.rnn(emb)\n",
    "        weights = torch.softmax(self.attn(rnn_out), dim=1)\n",
    "        context = torch.sum(weights * rnn_out, dim=1)\n",
    "        return self.sigmoid(self.fc(context))\n",
    "\n",
    "# === Bias/Fake Percentage Model ===\n",
    "class BiasScorer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, HIDDEN_DIM)\n",
    "        self.rnn = nn.GRU(HIDDEN_DIM, HIDDEN_DIM, batch_first=True)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        _, hidden = self.rnn(emb)\n",
    "        return self.sigmoid(self.fc(hidden.squeeze(0)))\n",
    "\n",
    "# === Real Fake News Examples ===\n",
    "REAL_TEXTS = [\n",
    "    \"Party A is a progressive party for the nation and good for youth. They believe in future reforms. Their leader spoke at a public rally today. Supporters are excited about the agenda. Critics call it a biased approach.\",\n",
    "    \"The new economic policy supports development. Government claims it benefits people. Prime minister announced it at parliament. Social media reacts with mixed opinions. Experts question the planâ€™s long-term impact.\",\n",
    "    \"Leaders of Party B talk about freedom and justice. Campaign speeches emphasize youth empowerment. Support grows across regions. Opposition says it's just a media stunt. Political analysts debate its authenticity.\",\n",
    "    \"Public support for new government reforms is rising. Parliament sessions see heated debates. President calls for unity and progress. Fake news spreads confusion among citizens. Experts urge verification of information.\",\n",
    "    \"Recent rally promoted a controversial statement. Social media amplifies biased views. Youth are targeted with emotional slogans. Critics warn of misinformation tactics. The campaign faces ethical scrutiny.\"\n",
    "]\n",
    "REAL_TOKENS = [torch.tensor(pad_sequence(tokenize(text)), dtype=torch.long) for text in REAL_TEXTS]\n",
    "\n",
    "# === Training ===\n",
    "def train(generator, discriminator, epochs=2000):\n",
    "    criterion = nn.BCELoss()\n",
    "    g_opt = optim.Adam(generator.parameters(), lr=0.001)\n",
    "    d_opt = optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "    last_fake = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        discriminator.zero_grad()\n",
    "        real_data = torch.stack(random.choices(REAL_TOKENS, k=16)).to(DEVICE)\n",
    "        real_labels = torch.ones(real_data.size(0), 1).to(DEVICE)\n",
    "\n",
    "        noise = torch.randn(real_data.size(0), SEQ_LEN, NOISE_DIM).to(DEVICE)\n",
    "        fake_logits = generator(noise)\n",
    "        fake_data = torch.argmax(fake_logits, dim=2).detach()\n",
    "        fake_labels = torch.zeros(real_data.size(0), 1).to(DEVICE)\n",
    "\n",
    "        d_loss_real = criterion(discriminator(real_data), real_labels)\n",
    "        d_loss_fake = criterion(discriminator(fake_data), fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        generator.zero_grad()\n",
    "        noise = torch.randn(real_data.size(0), SEQ_LEN, NOISE_DIM).to(DEVICE)\n",
    "        fake_logits = generator(noise)\n",
    "        fake_data = torch.argmax(fake_logits, dim=2)\n",
    "        output = discriminator(fake_data)\n",
    "        g_loss = criterion(output, torch.ones(real_data.size(0), 1).to(DEVICE))\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == epochs - 1:\n",
    "            fake_sample = fake_data[0].detach().cpu()\n",
    "            fake_text = detokenize(fake_sample.tolist())\n",
    "            lines = [f\"{i+1}. {line.strip().capitalize()}\" for i, line in enumerate(fake_text.split('.')[:5])]\n",
    "            print(f\"\\n[Epoch {epoch}] D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n",
    "            print(\"Generated Fake Article:\")\n",
    "            print('\\n'.join(lines))\n",
    "            last_fake = fake_sample\n",
    "\n",
    "    return last_fake\n",
    "\n",
    "# === Instantiate Models ===\n",
    "gen = Generator().to(DEVICE)\n",
    "disc = Discriminator().to(DEVICE)\n",
    "bias_model = BiasScorer().to(DEVICE)\n",
    "\n",
    "# === Train Models and Get Last Generated Fake ===\n",
    "last_generated = train(gen, disc)\n",
    "\n",
    "# === Evaluate Bias/Fake Score ===\n",
    "bias_model.eval()\n",
    "with torch.no_grad():\n",
    "    input_seq = last_generated.unsqueeze(0).to(DEVICE)  # [1, SEQ_LEN]\n",
    "    score = bias_model(input_seq).item()\n",
    "    print(f\"\\nðŸ§ª Bias/Fake Score: {round(score * 100, 2)}% likely to be fake or biased.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df460c-5c3f-41e7-8da3-fa7c58ac0b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
